---
- hosts: localhost
  connection: local
  tasks:
    - name: Install ingress-nginx
      shell: kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.47.0/deploy/static/provider/do/deploy.yaml

    - name: Wait for loadbalancer to be provisioned
      shell: kubectl -n ingress-nginx get svc ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
      register: lb_ip
      until: lb_ip.stdout | length > 0
      # max wait time 7m30s
      retries: 30
      delay: 15

    # Enable Pod communication through the Load Balancer
    # see step 5: https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-with-cert-manager-on-digitalocean-kubernetes
    # check with "kubectl describe orders -A"
    - name: List records
      uri:
        url: https://api.digitalocean.com/v2/domains/{{domain}}/records
        return_content: yes
        headers:
          Content-Type: "application/json"
          Authorization: "Bearer {{do_token}}"
      register: domain_records

    - name: Update A record if defined
      shell: doctl compute domain records update {{domain}} --record-id {{a_records[0]}} --record-data {{lb_ip.stdout}} --record-ttl 300
      when: a_records[0] is not undefined
      vars:
        a_records: '{{ domain_records.json | json_query("domain_records[?(@.type == ''A'' && @.name == ''lb'')].id")}}'

    - name: Create A record if not defined
      shell: doctl compute domain records create --record-type A --record-name lb --record-ttl 300 --record-data {{lb_ip.stdout}} {{domain}}
      when: a_records[0] is undefined
      vars:
        a_records: '{{ domain_records.json | json_query("domain_records[?(@.type == ''A'' && @.name == ''lb'')].id")}}'

    - include_tasks: ingress-nginx-digital-ocean-override.yaml
      vars:
        lb_domain: "lb.{{ domain }}"

    - name: Create monitoring namespace
      community.kubernetes.k8s:
        name: monitoring
        api_version: v1
        kind: Namespace
        state: present

    - name: Deploy setup-ingress chart from local path
      community.kubernetes.helm:
        name: setup-ingress
        chart_ref: ../setup/helm/charts/setup-ingress
        release_namespace: monitoring
        values:
          domain: "{{ domain }}"
          production: "{{ production | bool }}"

    # unfortunately using community.kubernetes.helm doesn't work correctly ("no token found"), use shell instead
    - name: Add ExternalDNS Repo
      shell: helm repo add bitnami https://charts.bitnami.com/bitnami

    - name: Update helm (not working via update_repo_cache)
      shell: helm repo update

    - name: Deploy ExternalDNS to automatically Manage DNS Records
      shell: helm install external-dns bitnami/external-dns --set provider=digitalocean,digitalocean.apiToken="{{ do_token }}",interval="1m",policy=sync -n kube-system

    - name: Install cert-manager CRDs
      shell: kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.3.1/cert-manager.crds.yaml

    - name: Add cert-manager helm repo
      community.kubernetes.helm_repository:
        name: jetstack
        repo_url: "https://charts.jetstack.io"

    - name: Deploy cert-manager
      community.kubernetes.helm:
        name: cert-manager
        chart_ref: jetstack/cert-manager
        chart_version: v1.3.1
        update_repo_cache: yes
        release_namespace: cert-manager
        create_namespace: true
        wait: yes

    - name: Wait for cert-manager to be fully provisioned
      shell: kubectl get pods --namespace cert-manager -o json
      register: cert_manager_result
      until: cert_manager_result.stdout|from_json|json_query('items[*].status.phase')|unique == ["Running"]
      # max wait time 2m
      retries: 12
      delay: 10

    - name: Deploy setup-issuer chart from local path
      community.kubernetes.helm:
        name: setup-issuer
        chart_ref: ../setup/helm/charts/setup-issuer
        release_namespace: cert-manager
        values:
          acmeMail: "{{ acme_mail }}"
          production: "{{ production | bool }}"

    - name: Add prometheus-community helm repo
      community.kubernetes.helm_repository:
        name: prometheus-community
        repo_url: "https://prometheus-community.github.io/helm-charts"

    - name: Deploy kube-prometheus-stack
      community.kubernetes.helm:
        name: prometheus
        chart_ref: prometheus-community/kube-prometheus-stack
        update_repo_cache: yes
        release_namespace: monitoring
        create_namespace: true
        # 16.6.4 breaks kube-state-metrics monitoring, wait till fix
        chart_version: 16.6.3
        values:
          prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues: false
          prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues: false

    - name: Deploy prometheus-adapter
      community.kubernetes.helm:
        name: prometheus-adapter
        chart_ref: prometheus-community/prometheus-adapter
        update_repo_cache: yes
        release_namespace: monitoring
        values_files:
          - ../setup/helm/values/prometheus-adapter-values.yaml

    - name: Add prometheus-statsd-exporter helm repo
      community.kubernetes.helm_repository:
        name: hahow
        repo_url: "https://hahow-helm-charts.storage.googleapis.com/"

    - name: Deploy prometheus-statsd-exporter
      community.kubernetes.helm:
        name: prometheus-statsd-exporter
        chart_ref: hahow/prometheus-statsd-exporter
        update_repo_cache: yes
        release_namespace: monitoring
        values_files:
          - ../setup/helm/values/prometheus-statsd-exporter-values.yaml

    - name: Add custom Grafana dashboards
      shell: "{{ item }}"
      with_items:
        # mqtt dashboard
        - kubectl -n monitoring create cm prometheus-kube-prometheus-mqtt --from-file ../setup/dashboards/mqtt.json
        - kubectl -n monitoring label cm prometheus-kube-prometheus-mqtt grafana_dashboard="1"
        # k6 dashboard
        - kubectl -n monitoring create cm prometheus-kube-prometheus-k6 --from-file ../setup/dashboards/k6.json
        - kubectl -n monitoring label cm prometheus-kube-prometheus-k6 grafana_dashboard="1"
